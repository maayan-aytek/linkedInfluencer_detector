{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling influencers users using LLM (Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def user_row_to_string(user_row):\n",
    "    \"\"\"\n",
    "    Converting user row (all his features) to a string\n",
    "    \"\"\"\n",
    "    user_string = \"\"\n",
    "    for key, value in user_row.items():\n",
    "        if isinstance(value, dict) or isinstance(value, list):\n",
    "            value_str = str(value)\n",
    "        else:\n",
    "            value_str = str(value) if value is not None else \"N/A\"\n",
    "        user_string += f\"{key}: {value_str}; \"\n",
    "    return user_string\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  # Nice display of the user row data\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "with open('secrets.json', 'r') as file:\n",
    "    secrets = json.load(file)\n",
    "\n",
    "    API_KEY = secrets['API_KEY']\n",
    "\n",
    "# Configuring Gemini API \n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Loading the data (after undersampling and preprocessing)\n",
    "users_df = pd.read_pickle(\"data/undersampled_df.pickle\")  \n",
    "users_df = users_df[[\"id\", \"followers\",  \"posts\", \"connections\", \"experience\", \"recommendations\", \"about\", \"position\", \"volunteer_experience\", \"education\", \"certifications\", \"languages\", \"сourses\", 'is_influencer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Influencers examples for the prompt \n",
    "influencers = users_df[users_df['is_influencer'] == 1]\n",
    "influencers_examples = []\n",
    "for i in range(4):\n",
    "    influencer = influencers.iloc[i]\n",
    "    influencers_examples.append(user_row_to_string(influencer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new influencers examples \n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "text_prompt  = f\"\"\"\n",
    "Generate a new example of Linkedin users influencer based on the examples I will give you. The example should:\n",
    "- Have valid values in all columns.\n",
    "- Maintain the same structure and format as given examples.\n",
    "- Exhibit characteristics typical of influencers that you can infer from the given examples, but create new examples that won't be too similar to the given ones.\n",
    "- connections feature should range between 0 to 500 maximum.\n",
    "- The label for influencers is 'is_influencer' = 1. So this should be the value for this feature since you are generating influencers.\n",
    "- Features in generated examples are separated with ';'.\n",
    "Here are four examples of influencers you should base upon when generating new examples:\n",
    "    - Example Influencer 1: {influencers_examples[0]}\n",
    "    - Example Influencer 2: {influencers_examples[1]}\n",
    "    - Example Influencer 3: {influencers_examples[2]}\n",
    "    - Example Influencer 4: {influencers_examples[3]}\n",
    "- Generate the full example within your tokens limit.\n",
    "\"\"\"\n",
    "examples = []\n",
    "for i in range(20):\n",
    "    response = model.generate_content(text_prompt)\n",
    "    examples.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove examples which the LLM didn't finish to write (don't finish with is_influencer: 1;)\n",
    "valid_examples = []\n",
    "for example in examples:\n",
    "    if example[-2:] == '1;':\n",
    "        valid_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "failed\n",
      "failed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def string_to_df_row(input_string):\n",
    "    \"\"\"\n",
    "    Fixing LLM Output and converting the text to pd dataframe row\n",
    "    \"\"\"\n",
    "    input_string = input_string.replace('\\\\n', '')\n",
    "    input_string = input_string.replace('[], is_influencer: 1;', '[]; is_influencer: 1;')\n",
    "    input_string = input_string.replace(\"'position\", \"position\")\n",
    "    input_string = input_string.replace(', education', '; education')\n",
    "    input_string = input_string.replace(', about', '; about')\n",
    "    input_string = input_string.replace(', languages', '; languages')\n",
    "    input_string = input_string.replace(', сourses', '; сourses')\n",
    "    input_string = input_string.replace(', is_influencer', '; is_influencer')\n",
    "    input_string = input_string.replace(', connections', '; connections')\n",
    "    input_string = input_string.replace(', posts', '; posts')\n",
    "    input_string = input_string.replace(', followers', '; followers')\n",
    "    input_string = input_string.replace(', experience', '; experience')\n",
    "    input_string = input_string.replace(', volunteer_experience', '; volunteer_experience')\n",
    "    input_string = input_string.replace(', position', '; position')\n",
    "    input_string = input_string.replace(', certifications', '; certifications')\n",
    "    input_string = input_string.replace(\", 'education\", \"; education\")\n",
    "    input_string = input_string.replace(\"'education\", \"education\")\n",
    "    input_string = input_string.replace(\"education'\", \"education\")\n",
    "    \n",
    "    input_string = input_string.replace(\", 'education'\", \"; education\")\n",
    "    input_string = input_string.replace(\", 'about'\", \"; about\")\n",
    "    input_string = input_string.replace(\", 'languages'\", \"; languages\")\n",
    "    input_string = input_string.replace(\", 'сourses'\", \"; сourses\")\n",
    "    input_string = input_string.replace(\", 'is_influencer'\", \"; is_influencer\")\n",
    "    input_string = input_string.replace(\", is_influencer\", \"; is_influencer\")\n",
    "    input_string = input_string.replace(\", 'connections'\", \"; connections\")\n",
    "    input_string = input_string.replace(\", 'posts'\", \"; posts\")\n",
    "    input_string = input_string.replace(\", 'followers'\", \"; followers\")\n",
    "    input_string = input_string.replace(\", 'experience'\", \"; experience\")\n",
    "    input_string = input_string.replace(\", 'volunteer_experience'\", \"; volunteer_experience\")\n",
    "    input_string = input_string.replace(\", 'position'\", \"; position\")\n",
    "    input_string = input_string.replace(\"position'\", \"position\")\n",
    "    input_string = input_string.replace(\", 'certifications'\", \"; certifications\")\n",
    "    input_string = input_string.replace(\"'is_influencer\", \"is_influencer\")\n",
    "    input_string = input_string.replace(\"is_influencer'\", \"is_influencer\")\n",
    "    input_string = input_string.replace(\"1;\", \"1\")\n",
    "    input_string = input_string.replace(\",\\nis_influencer\", \"; is_influencer\")\n",
    "    feature_list = input_string.split('; ')\n",
    "    \n",
    "    data = {}\n",
    "    for feature in feature_list:\n",
    "        key, value = feature.split(': ', 1)\n",
    "        try:\n",
    "            data[key] = ast.literal_eval(value)\n",
    "        except (ValueError, SyntaxError):\n",
    "            data[key] = value\n",
    "    df = pd.DataFrame([data])\n",
    "    \n",
    "    return df\n",
    "\n",
    "expected_columns = set(influencers.columns)\n",
    "examples_df = pd.DataFrame()\n",
    "for example in valid_examples:\n",
    "    try:\n",
    "        # Remove examples out of format\n",
    "        df_example = string_to_df_row(example)\n",
    "        if not set(df_example.columns).issubset(expected_columns):\n",
    "            continue\n",
    "        examples_df = pd.concat([examples_df, df_example])\n",
    "    except: \n",
    "        print(\"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_pickle(\"data/undersampled_df.pickle\")\n",
    "original_df = original_df[['about', 'connections', 'is_influencer', 'certifications',\n",
    "       'education', 'experience', 'followers',\n",
    "       'languages', 'position', 'posts',\n",
    "       'recommendations', 'recommendations_count', 'volunteer_experience',\n",
    "       'сourses', 'certifications_count', 'volunteer_experience_count',\n",
    "       'сourses_count', 'education_count', 'experience_count', 'posts_count',\n",
    "       'languages_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features for the new examples that existing in the original_df\n",
    "examples_df['certifications_count'] = examples_df['certifications'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['volunteer_experience_count'] = examples_df['volunteer_experience'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['сourses_count'] = examples_df['сourses'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['education_count'] = examples_df['education'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['experience_count'] = examples_df['experience'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['posts_count'] = examples_df['posts'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['languages_count'] = examples_df['languages'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "examples_df['recommendations_count'] = examples_df['recommendations'].apply(lambda x: len(x) if isinstance(x, list) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Heuristic for removing bad examples\n",
    "examples_df = examples_df.dropna(subset=['certifications_count', 'volunteer_experience_count', 'сourses_count', 'education_count', 'experience_count', 'posts_count', 'languages_count'])\n",
    "examples_df = examples_df[['about', 'connections', 'is_influencer', 'certifications',\n",
    "       'education', 'experience', 'followers',\n",
    "       'languages', 'position', 'posts',\n",
    "       'recommendations', 'recommendations_count', 'volunteer_experience',\n",
    "       'сourses', 'certifications_count', 'volunteer_experience_count',\n",
    "       'сourses_count', 'education_count', 'experience_count', 'posts_count',\n",
    "       'languages_count']]\n",
    "\n",
    "# Add the new examples to the original_df and save the final data to pickle\n",
    "df_for_modeling = pd.concat([original_df, examples_df])\n",
    "df_for_modeling.to_pickle('df_for_modeling.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
